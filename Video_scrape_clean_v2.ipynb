{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30e5ae26-b203-4e58-a5a1-907c498000bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No subtitles found for https://www.youtube.com/watch?v=oLhZVRphhew . Skipping.\n",
      "No subtitles found for https://www.youtube.com/watch?v=8qfndbEYroE . Skipping.\n",
      "No subtitles found for https://www.youtube.com/watch?v=kZZez42HWvU . Skipping.\n",
      "Download and cleaning completed!\n",
      "Skipped videos:\n",
      "https://www.youtube.com/watch?v=oLhZVRphhew \n",
      "https://www.youtube.com/watch?v=8qfndbEYroE \n",
      "https://www.youtube.com/watch?v=kZZez42HWvU \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define base directory for saving files\n",
    "base_directory = r\"C:\\Users\\krgod\\Documents\\Texas MSBA\\Fall Semester\\Advanced Machine Learning\\Final Project\"\n",
    "\n",
    "# Define folder paths\n",
    "subtitles_folder = os.path.join(base_directory, \"subtitles_test_v3\")\n",
    "cleaned_subtitles_folder = os.path.join(base_directory, \"cleaned_subtitles_test_v3\")\n",
    "\n",
    "# Create folders if they don't exist\n",
    "os.makedirs(subtitles_folder, exist_ok=True)\n",
    "os.makedirs(cleaned_subtitles_folder, exist_ok=True)\n",
    "\n",
    "# Function to clean subtitles\n",
    "def clean_subtitles(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Cleans up a subtitle file by keeping timestamps and content including [Applause] and [Laughter],\n",
    "    removing unnecessary metadata, inline tags, and avoiding repeated subtitle lines across timestamps.\n",
    "    Args:\n",
    "    - input_file (str): Path to the input subtitle file.\n",
    "    - output_file (str): Path to the output cleaned subtitle file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "            lines = infile.readlines()\n",
    "\n",
    "        cleaned_lines = []\n",
    "        seen_lines = set()  # Track unique subtitles globally\n",
    "        timestamp_pattern = r\"^\\d{2}:\\d{2}:\\d{2}\\.\\d{3} --> \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\"\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Keep lines with timestamps but remove align and position metadata\n",
    "            if re.match(timestamp_pattern, line):\n",
    "                cleaned_timestamp = re.sub(r\" align:.*$\", \"\", line)\n",
    "                cleaned_lines.append(cleaned_timestamp)\n",
    "                continue\n",
    "\n",
    "            # Keep non-empty lines, including [Applause] and [Laughter], and remove inline tags\n",
    "            if line and not re.search(r\"align:start|position:\\d+%\", line):\n",
    "                # Remove inline HTML-like tags such as <c>...</c> or <00:...>\n",
    "                cleaned_line = re.sub(r\"<[^>]*>\", \"\", line)\n",
    "\n",
    "                # Add line only if it hasn't been seen before\n",
    "                if cleaned_line not in seen_lines:\n",
    "                    cleaned_lines.append(cleaned_line)\n",
    "                    seen_lines.add(cleaned_line)\n",
    "\n",
    "        # Write cleaned lines to the output file\n",
    "        with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            for line in cleaned_lines:\n",
    "                outfile.write(line + '\\n')\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning subtitles {input_file}: {e}\")\n",
    "\n",
    "# Load the CSV file containing YouTube links\n",
    "csv_file_path = \"comedy_vid_links_v2_test.csv\"  # Replace with the actual path to your CSV file\n",
    "\n",
    "try:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Assume the YouTube links are in the first column\n",
    "    youtube_links = df.iloc[:, 0].dropna().tolist()\n",
    "    \n",
    "    # List to track skipped videos\n",
    "    skipped_videos = []\n",
    "\n",
    "    # Loop through each link and download subtitles\n",
    "    for link in youtube_links:\n",
    "        try:\n",
    "            # Step 1: Try to download manual captions\n",
    "            manual_subtitles_success = False\n",
    "            for attempt in range(3):\n",
    "                subtitles_command = f'yt-dlp --write-sub --sub-langs \"en,en.*\" --skip-download -o \"{subtitles_folder}/%(title)s_%(id)s.manual.%(ext)s\" \"{link}\"'\n",
    "                result = os.system(subtitles_command)\n",
    "                if result == 0:\n",
    "                    manual_subtitles_success = True\n",
    "                    break\n",
    "                print(f\"Manual subtitle download failed for {link}, attempt {attempt + 1}/3.\")\n",
    "                time.sleep(5)\n",
    "\n",
    "            # Step 2: If manual captions fail, try auto-generated captions\n",
    "            if not manual_subtitles_success:\n",
    "                print(f\"Manual subtitles unavailable for {link}. Attempting auto-generated subtitles.\")\n",
    "                auto_subtitles_success = False\n",
    "                for attempt in range(3):\n",
    "                    auto_subtitles_command = f'yt-dlp --write-auto-sub --sub-langs \"en,en.*\" --skip-download -o \"{subtitles_folder}/%(title)s_%(id)s.auto.%(ext)s\" \"{link}\"'\n",
    "                    result = os.system(auto_subtitles_command)\n",
    "                    if result == 0:\n",
    "                        auto_subtitles_success = True\n",
    "                        break\n",
    "                    print(f\"Auto-generated subtitle download failed for {link}, attempt {attempt + 1}/3.\")\n",
    "                    time.sleep(5)\n",
    "\n",
    "                if not auto_subtitles_success:\n",
    "                    print(f\"Subtitle download failed after 3 attempts for {link}. Skipping.\")\n",
    "                    skipped_videos.append(link)\n",
    "                    continue\n",
    "            \n",
    "            # Process subtitles (manual if available, otherwise auto-generated)\n",
    "            processed = False\n",
    "            for file_name in os.listdir(subtitles_folder):\n",
    "                if file_name.endswith(\".vtt\") and link.split(\"v=\")[-1] in file_name:\n",
    "                    input_file = os.path.join(subtitles_folder, file_name)\n",
    "                    output_file = os.path.join(cleaned_subtitles_folder, file_name)\n",
    "                    clean_subtitles(input_file, output_file)\n",
    "                    processed = True\n",
    "                    break\n",
    "            \n",
    "            if not processed:\n",
    "                print(f\"No subtitles found for {link}. Skipping.\")\n",
    "                skipped_videos.append(link)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing link {link}: {e}\")\n",
    "            skipped_videos.append(link)\n",
    "\n",
    "    # Print summary of skipped videos\n",
    "    print(\"Download and cleaning completed!\")\n",
    "    if skipped_videos:\n",
    "        print(\"Skipped videos:\")\n",
    "        for video in skipped_videos:\n",
    "            print(video)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfced7cc-71f6-44da-b9da-7df55323bdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
